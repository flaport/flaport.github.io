<!DOCTYPE html>
  
<html lang="en">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <title>Flaport.net | A Fully connected neural network in JAX</title>
    
    
    <meta name="description" content="JAX is the hot new ML-tool on the block. I’m currently trying to get acquinted with it. The first thing I usually do to get to know a tool like this is to make a simple neural network to solve the MNIST digit recognition task. So here we go…">
    
    <link rel="shortcut icon" type="image/svg" href="/static/img/icon.svg" />
    <link rel="stylesheet" href="/static/css/normalize.css" type="text/css" />
    <link rel="stylesheet" href="/static/css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="/static/css/main.css" type="text/css" />
    <link rel="stylesheet" href="/static/css/colors.css" type="text/css" />
     
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [
            ["$", "$"],
            ["\\(", "\\)"],
          ],
        },
      };
    </script>
     
    <!-- Matomo -->
    <script type="text/javascript">
      var _paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
      _paq.push(["setCookieDomain", "*.flaport.net"]);
      _paq.push(["setDoNotTrack", true]);
      _paq.push(["trackPageView"]);
      _paq.push(["enableLinkTracking"]);
      (function () {
        var u = "//matomo.flaport.net/";
        _paq.push(["setTrackerUrl", u + "matomo.php"]);
        _paq.push(["setSiteId", "1"]);
        var d = document,
          g = d.createElement("script"),
          s = d.getElementsByTagName("script")[0];
        g.type = "text/javascript";
        g.async = true;
        g.defer = true;
        g.src = u + "matomo.js";
        s.parentNode.insertBefore(g, s);
      })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body>
    <div class="document">
      <div class="contentwrapper">
        <div class="noprint" align="right">
          <span class="fa tooltip hideborder" style="cursor: default;">
            &nbsp;
            <span class="tooltiptext">toggle dark mode</span>
          </span>
          <span class="fa tooltip hideborder" style="cursor: default;">
            <input type="checkbox" class="noprint" id="darkmodetoggle" />
            <span class="tooltiptext">toggle dark mode</span>
          </span>
        </div>

        <div class="content">
          
    <h1>A Fully connected neural network in JAX</h1>
<!-- author: Flaport&nbsp;&middot; -->
posted on <a href="#" class="date">2020-12-25T14:48:19Z</a>

&middot;&nbsp;view page on <a href="https://github.com/flaport/blog/blob/master/posts/fully-connected-neural-network-in-jax.ipynb">GitHub</a>

<div style="padding-top: 3pt">
tags:

    

<a class="tag tooltip" href="/tags/ml/">ml<sup>&nbsp;(7)</sup><span class="tooltiptext">machine learning</span></a>



    

<a class="tag tooltip" href="/tags/python/">python<sup>&nbsp;(6)</sup></a>



    

<span class="currenttag tooltip">computer vision<sup>&nbsp;(3)</sup></span>



    

<a class="tag tooltip" href="/tags/jax/">jax<sup>&nbsp;(1)</sup></a>



</div>

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>JAX is the hot new ML-tool on the block. I'm currently trying to get acquinted with it. The first thing I usually do to get to know a tool like this is to make a simple neural network to solve the MNIST digit recognition task. So here we go...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imports">Imports<a class="anchor-link" href="#Imports">&#182;</a></h2><p>We only need JAX, JAX optimizers, the JAX version of Numpy and matplotlib for plotting...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.experimental.optimizers</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fetch-MNIST">Fetch MNIST<a class="anchor-link" href="#Fetch-MNIST">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To reduce the dependencies on external tools, I wrote my own function to fetch the MNIST dataset directly from Yann Lecun's website...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fetch_mnist</span><span class="p">(</span><span class="n">directory</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s2">&quot;mnist_data&quot;</span><span class="p">,</span> <span class="n">redownload</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Get MNIST data in npy format</span>

<span class="sd">    Args:</span>
<span class="sd">        directory: directory to download the MNIST dataset into</span>
<span class="sd">        redownload: force redownload, even if file already exists</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">directory</span><span class="p">))</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">redownload</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train.npy&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test.npy&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train.npy&#39;</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test.npy&#39;</span><span class="p">)</span>
        
    <span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
    <span class="k">if</span> <span class="n">redownload</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train_images.gz&#39;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;downloading train images from &#39;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&#39;&quot;</span><span class="p">)</span>
        <span class="n">urlretrieve</span><span class="p">(</span><span class="s1">&#39;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train_images.gz&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">redownload</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train_labels.gz&#39;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;downloading train labels from &#39;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&#39;&quot;</span><span class="p">)</span>
        <span class="n">urlretrieve</span><span class="p">(</span><span class="s1">&#39;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train_labels.gz&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">redownload</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test_images.gz&#39;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;downloading test images from &#39;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&#39;&quot;</span><span class="p">)</span>
        <span class="n">urlretrieve</span><span class="p">(</span><span class="s1">&#39;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test_images.gz&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">redownload</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test_labels.gz&#39;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;downloading test labels from &#39;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&#39;&quot;</span><span class="p">)</span>
        <span class="n">urlretrieve</span><span class="p">(</span><span class="s1">&#39;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test_labels.gz&#39;</span><span class="p">)</span>

    <span class="c1"># empty arrays to fill (jax numpy arrays are immuable, hence the use of standard numpy):</span>
    <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">empty</span><span class="p">,</span> <span class="n">uint8</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">785</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">uint8</span><span class="p">)</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">785</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">uint8</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;converting .gz data to .npy&#39;</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">gzip</span>
    <span class="k">for</span> <span class="nb">type</span><span class="p">,</span> <span class="n">npdata</span> <span class="ow">in</span> <span class="p">[(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">)]:</span>
        <span class="c1"># open the files</span>
        <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/%s_images.gz&#39;</span><span class="o">%</span><span class="k">type</span>, &#39;rb&#39;) as data,\
             <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/%s_labels.gz&#39;</span><span class="o">%</span><span class="k">type</span>, &#39;rb&#39;) as labels:

            <span class="c1"># skip the first bytes with metadata of the ubyte file:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
            <span class="n">labels</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>

            <span class="c1"># read each byte of the gzip file and save it as a uint8 number</span>
            <span class="c1"># in the numpy array.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">npdata</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">npdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">784</span><span class="p">):</span> <span class="c1"># append the data after the label</span>
                    <span class="n">npdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                    
    <span class="n">train</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

    <span class="c1"># save numpy arrays</span>
    <span class="n">jnp</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/train.npy&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">jnp</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">directory</span><span class="si">}</span><span class="s1">/test.npy&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;finished conversion.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data">Data<a class="anchor-link" href="#Data">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The image values are specified by integers between 0 and 255. We convert these pixel values to floats between 0 and 1. Moreover, we split the data in a training set of 50000 images, a validation set of 10000 images and a test set of 10000 images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_size</span><span class="p">,</span> <span class="n">valid_size</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">fetch_mnist</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">])</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="o">-</span><span class="n">test_size</span><span class="o">-</span><span class="n">valid_size</span><span class="p">]</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">test_size</span><span class="o">-</span><span class="n">valid_size</span><span class="p">:</span><span class="o">-</span><span class="n">test_size</span><span class="p">]</span>
<span class="n">test_data</span>  <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">test_size</span><span class="p">:]</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">get_values_labels</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
    <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">labels</span>

<span class="n">train_values</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">get_values_labels</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">valid_values</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">get_values_labels</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span>
<span class="n">test_values</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">get_values_labels</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">num_pixels</span> <span class="o">=</span> <span class="n">train_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">num_labels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_labels</span><span class="o">.</span><span class="n">max</span><span class="p">())</span><span class="o">+</span><span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train data shape:</span><span class="se">\t</span><span class="si">{</span><span class="n">train_values</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train labels shape:</span><span class="se">\t</span><span class="si">{</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train data shape:	(50000, 784)
train labels shape:	(50000,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can visualize the different digits by writing a visualization function that reshapes the 784D train and test values into a 28x28 grid:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_digit</span><span class="p">(</span><span class="n">digit_array</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">digit_array</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
<span class="n">show_digit</span><span class="p">(</span><span class="n">train_values</span><span class="p">[</span><span class="mi">31</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Random-numbers-in-JAX">Random numbers in JAX<a class="anchor-link" href="#Random-numbers-in-JAX">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Maybe it's time to quickly talk about random numbers in JAX. They are generated differently than in Numpy. The main reason for this is to make it easier to paralellize random number generation over multiple devices. To generate random numbers, a Pseudo Random Number Generator (PRNG) Key needs to be defined from a seed:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>now, to generate random numbers, the key first needs to be split into a key to use later and a key to use right now:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prng</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">prng</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[6]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>DeviceArray([[-1.6652092 ,  0.23443979, -0.24498989],
             [ 0.44707215, -0.37714297,  0.28259823],
             [-0.11017016,  0.5699527 ,  0.33960482]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This procedure is repeated every time a new random array needs to be generated.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model">Model<a class="anchor-link" href="#Model">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's make a simple three layer fully connected neural network. Due to JAX's functional nature it's often good practice (and a lot easier) to keep the model parameters together in a dictionary:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prng</span><span class="p">,</span> <span class="n">w1key</span><span class="p">,</span> <span class="n">b1key</span><span class="p">,</span> <span class="n">w2key</span><span class="p">,</span> <span class="n">b2key</span><span class="p">,</span> <span class="n">w3key</span><span class="p">,</span> <span class="n">b3key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">prng</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">num_hidden1</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">num_hidden2</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="o">*</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">w1key</span><span class="p">,</span> <span class="p">(</span><span class="n">num_pixels</span><span class="p">,</span> <span class="n">num_hidden1</span><span class="p">)),</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="o">*</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">b1key</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden1</span><span class="p">)),</span>
    <span class="n">w2</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="o">*</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">w2key</span><span class="p">,</span> <span class="p">(</span><span class="n">num_hidden1</span><span class="p">,</span> <span class="n">num_hidden2</span><span class="p">)),</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="o">*</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">b2key</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden2</span><span class="p">)),</span>
    <span class="n">w3</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="o">*</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">w3key</span><span class="p">,</span> <span class="p">(</span><span class="n">num_hidden2</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)),</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="o">*</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">b3key</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="nd">@params</span><span class="p">[</span><span class="s2">&quot;w1&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="nd">@params</span><span class="p">[</span><span class="s2">&quot;w2&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="nd">@params</span><span class="p">[</span><span class="s2">&quot;w3&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b3&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We use the categorical cross entropy loss for training the model. We define this loss function ourselves  as JAX does not off loss primitives (try to figure out what's going on!). For this we use both <a href="https://jax.readthedocs.io/en/latest/jax.html?highlight=jit#jax.jit">jax.jit</a> and <a href="https://jax.readthedocs.io/en/latest/jax.html?highlight=jit#jax.vmap">jax.vmap</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">xeloss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">_elementwise_xeloss</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="o">-</span><span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="n">y</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">_elementwise_xeloss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's also useful to define an accuracy function...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Due to the functional nature of JAX, it's also useful to define a forward function that yields just the loss (in stead of the logits).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">lossforward</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">xeloss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As optimizer we could use a Gradient Descent optimizer [with or without decaying learning rate] or one of the more sophisticated (and easier to optimize) optimizers like Adam or RMSProp. We're going for the adam optimizer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">optim_init</span><span class="p">,</span> <span class="n">optim_update</span><span class="p">,</span> <span class="n">optim_params</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">optim_state</span> <span class="o">=</span> <span class="n">optim_init</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is where the functional nature of JAX shows itself again... as can be seen above, creating an optimizer just creates three functions: an initialization function with which to initialize the optimizer state, an update function which will update the optimizer state (and with it the model parameters). The third function that's being returned will give the model parameters given the optimizer state.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>given all this, we can define a single training step:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">optim_state</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">optim_params</span><span class="p">(</span><span class="n">optim_state</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">lossforward</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optim_state</span> <span class="o">=</span> <span class="n">optim_update</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">optim_state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optim_state</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we can start the training:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">step</span><span class="o">%</span><span class="k">200</span> == 0 or step == num_steps - 1:
        <span class="n">valid_logits</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">optim_params</span><span class="p">(</span><span class="n">optim_state</span><span class="p">),</span> <span class="n">valid_values</span><span class="p">)</span>
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">xeloss</span><span class="p">(</span><span class="n">valid_logits</span><span class="p">,</span> <span class="n">valid_labels</span><span class="p">)</span>
        <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">valid_logits</span><span class="p">,</span> <span class="n">valid_labels</span><span class="p">)</span>
        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">step</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="n">valid_accuracy</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="s2">5.0f</span><span class="si">}</span><span class="se">\t</span><span class="s2"> Valid. Acc. = </span><span class="si">{</span><span class="n">valid_accuracy</span><span class="si">:</span><span class="s2">5.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">prng</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">prng</span><span class="p">)</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">train_size</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">train_values</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">optim_state</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">optim_state</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Step     0	 Valid. Acc. = 11.00
Step   200	 Valid. Acc. = 94.14
Step   400	 Valid. Acc. = 96.26
Step   600	 Valid. Acc. = 96.38
Step   800	 Valid. Acc. = 97.06
Step  1000	 Valid. Acc. = 97.47
Step  1200	 Valid. Acc. = 97.26
Step  1400	 Valid. Acc. = 97.32
Step  1600	 Valid. Acc. = 97.75
Step  1800	 Valid. Acc. = 97.68
Step  1999	 Valid. Acc. = 97.50
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can visualize the training history:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">steps</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">history</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax_loss</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax_acc</span> <span class="o">=</span> <span class="n">ax_loss</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">sca</span><span class="p">(</span><span class="n">ax_acc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy [%]&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">90</span><span class="p">,</span><span class="mi">95</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">sca</span><span class="p">(</span><span class="n">ax_loss</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Log Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mf">1.1</span><span class="o">*</span><span class="nb">max</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">+</span><span class="mi">100</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Training Steps&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Validation Loss / Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test">Test<a class="anchor-link" href="#Test">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, the accuracy on the test set can be evaluated:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">optim_params</span><span class="p">(</span><span class="n">optim_state</span><span class="p">)</span>
<span class="n">test_logits</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">test_values</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">test_logits</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test Accuracy = </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">5.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Accuracy = 97.51
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Visualize an example</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">315</span>
<span class="n">show_digit</span><span class="p">(</span><span class="n">test_values</span><span class="p">[</span><span class="n">N</span><span class="p">])</span>
<span class="n">test_logits</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">test_values</span><span class="p">[</span><span class="n">N</span><span class="p">:</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[</span><span class="n">N</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;prediction=</span><span class="si">{</span><span class="n">prediction</span><span class="si">}</span><span class="se">\t</span><span class="s1">target=</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGvklEQVR4nO3dTYiNfx/H8TP6h8ZjfzMpm3sWYoPV2cmCzdjYsZKdBSsWZDlEWaFIkYUaa2GUPGyxYCQLUghFKZKnJE/nXt2LO873mBlj5jNer+1nrnOuGm/X1K8z09VqtRrA5Ddtom8A+DVihRBihRBihRBihRBihRD/jOSLe3p6Wn19feN0K8CTJ08ar1696vrZNqJY+/r6GsPDw7/nroAfNJvNtpsfgyGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCHEPxN9AzQaz58/b7vdv3+/vPbw4cPlPjQ0VO6HDh0q9+XLl7fdent7y2tXrFhR7oyMJyuEECuEECuEECuEECuEECuEcHTzCz5+/FjuN2/eLPcjR46U+927d9tuDx8+LK/tZNq0+v/jnTt3jvq1//3333JftWpVuQ8ODpZ7d3f3iO9pKvNkhRBihRBihRBihRBihRBihRBihRDOWX/BwMBAuR88eLDcO511pnr9+nW5nzt3rtzXrl1b7tXH++bPn19eOxVNzX9FMAWJFUKIFUKIFUKIFUKIFUKIFUI4Z200Go8fPy73Fy9ejOv7L1mypO128eLF8tq5c+f+7tv5P1euXGm7HT16tLz26tWr5X7t2rVy37Bhw6jua6ryZIUQYoUQYoUQYoUQYoUQYoUQYoUQf805a/W7ffv7+8tr379/P6b3PnDgQLmvX7++7bZo0aIxvfdYVfdW/TnIRqPRWLZs2Zje+9atW2234eHh8tpmszmm956MPFkhhFghhFghhFghhFghhFghhFghhHPWRqPx9u3b8tp169aV+5YtW8q90+/HTbV06dJy//LlS7l3dXWVe/V9cc4KTFpihRBihRBihRBihRBihRBT5ujm+/fv5V4dA3T6k4zbtm0r99WrV5f7VPXu3bty7/Q92b9/f7kPDg623Xp6esprpyJPVgghVgghVgghVgghVgghVgghVggxZc5ZP3/+XO63b9/+Q3eS5dOnT+V+8uTJttvu3bvLa1+/fl3u27dvL/d79+6V+9/GkxVCiBVCiBVCiBVCiBVCiBVCiBVCTJlz1pkzZ5Z79ZnTM2fOlNfeuXNn1K893l6+fFnunc46BwYGyv306dMjvifGhycrhBArhBArhBArhBArhBArhBArhJgy56zjaefOneX+7Nmzct+6dWu5Hzt2bMT39D+XLl0q97t375Z7p9+ZzOThOwUhxAohxAohxAohxAohxAohxAohulqt1i9/cbPZbA0PD4/j7UyMJUuWlPujR4/KvdPfIZ3Is8zJfG/fvn2bsPeerJrNZmN4eLjrZ5snK4QQK4QQK4QQK4QQK4QQK4TwEblG54+orV+/vtzfvn1b7hN5PDJ37txyX7BgQbk/ffp01O+9cOHCUV/LjzxZIYRYIYRYIYRYIYRYIYRYIYRYIYRz1kajsWbNmnK/fPlyuXf62ODhw4fL/cGDB223ffv2ldfOmzev3JvNZrkvXry43Ht7e8u9curUqVFfy488WSGEWCGEWCGEWCGEWCGEWCGEWCGEc9Zf0OmsstO+adOmcv/69Wvbbc6cOeW1nT4r++HDh3LfvHlzuVf6+/vLfeXKlaN+bX7kyQohxAohxAohxAohxAohxAohxAohnLP+AbNmzZqw9964cWO5X7hwYdSv3d3dXe7Tp08f9WvzI09WCCFWCCFWCCFWCCFWCCFWCOHoJtzDhw/LfWhoqNzH8ucoT5w4MeprGTlPVgghVgghVgghVgghVgghVgghVgjhnDXc8ePHy73TOeqMGTPKfWBgoO02kR/9+xt5skIIsUIIsUIIsUIIsUIIsUIIsUII56yT3Js3b8r9xo0bY3r9vr6+ct+1a9eYXp/fx5MVQogVQogVQogVQogVQogVQogVQjhnneT27NlT7tevX/9Dd8JE82SFEGKFEGKFEGKFEGKFEGKFEGKFEM5ZJ7m9e/eW++PHj8v9/Pnz5b5jx44R3xMTw5MVQogVQogVQogVQogVQogVQji6meRmz55d7mfPnv0zN8KE82SFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEF2tVuvXv7ir62Wj0Xg6frcDf73/tFqt3p8NI4oVmDh+DIYQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQ/wUNBxC3u/Me5gAAAABJRU5ErkJggg==
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>prediction=9	target=9
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's it! A very simple example on how to use JAX.</p>

</div>
</div>
</div>
 



<br>
<hr>
If you like this post, consider leaving a comment or <a href="https://github.com/flaport/blog/blob/master/posts/fully-connected-neural-network-in-jax.ipynb">star it on GitHub</a>.

<script data-isso="//isso.flaport.net/" src="//isso.flaport.net/js/embed.min.js"></script>
<style>
#isso-thread > h4 {
    color: var(--color15);
    font-weight: bold;
}
</style>
<section id="isso-thread"></section>


        </div>
      </div>

      <div class="sidebar">
        <div class="sidebarwrapper">
          <img id="logo" src="/static/img/logo.svg" />
          <ul>
            
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a href="/">Home</a>
            </li>
             
            <li class="toctree-l1">
              <span class="fa" style="font-size: 14px;"></span>&nbsp;<a
                href="/tags/cv/"
                >computer vision</a
              >
                
              <a class="fa tooltip hideborder" href="/fully-connected-neural-network-in-jax.html"
                >
                <span class="tooltiptext"
                  >exit [cv] tag view</span
                >
              </a>
            </li>
               
            <li class="toctree-l1">
              
              <span class="fa"></span>&nbsp;<a
                href="/tags/cv/yolo-part-2.html"
                >Older [cv] post</a
              >
              
            </li>
            
            <h3 style="padding-top: 1em;">
              Tags&nbsp;<span class="fa" style="font-size: 18px;"></span>
            </h3>
             

<a class="tag tooltip" href="/tags/ml/">ml<sup>&nbsp;(7)</sup><span class="tooltiptext">machine learning</span></a>

  

<a class="tag tooltip" href="/tags/python/">python<sup>&nbsp;(6)</sup></a>

  

<span class="currenttag tooltip">computer vision<sup>&nbsp;(3)</sup></span>

  

<a class="tag tooltip" href="/tags/rl/">rl<sup>&nbsp;(3)</sup><span class="tooltiptext">reinforcement learning</span></a>

  

<a class="tag tooltip" href="/tags/linux/">linux<sup>&nbsp;(2)</sup></a>

  

<a class="tag tooltip" href="/tags/yolo/">yolo<sup>&nbsp;(2)</sup></a>

  

<a class="tag tooltip" href="/tags/c++/">c++<sup>&nbsp;(1)</sup></a>

  

<a class="tag tooltip" href="/tags/game/">game<sup>&nbsp;(1)</sup></a>

  

<a class="tag tooltip" href="/tags/javascript/">javascript<sup>&nbsp;(1)</sup></a>

  

<a class="tag tooltip" href="/tags/jax/">jax<sup>&nbsp;(1)</sup></a>

  

<a class="tag tooltip" href="/tags/vps/">vps<sup>&nbsp;(1)</sup></a>

 
            <h3 style="padding-top: 1em;">
              Projects&nbsp;<span class="fa" style="font-size: 18px;"></span>
            </h3>
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a href="https://photontorch.com"
                >Photontorch</a
              >
            </li>
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a
                href="https://github.com/flaport/fdtd"
                >Python&nbsp;3D&nbsp;FDTD</a
              >
            </li>
            <h3 style="padding-top: 1em;">
              External links&nbsp;<span class="fa" style="font-size: 18px;"
                ></span
              >
            </h3>
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a
                href="/index.xml"
                target="_blank"
                >RSS</a
              >
            </li>
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a
                href="https://github.com/flaport"
                >GitHub</a
              >
            </li>
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a
                href="https://twitter.com/florislaporte"
                >Twitter</a
              >
            </li>
            <li class="toctree-l1">
              <span class="fa"></span>&nbsp;<a
                href="https://linkedin.com/in/florislaporte"
                >Linked in</a
              >
            </li>
            <li class="toctree-l1">
              <span class="fa" style="font-size: 72%;"></span>&nbsp;<a
                href="https://www.photonics.intec.ugent.be/contact/people.asp?ID=424"
                >Academic&nbsp;Profile</a
              >
            </li>
            <li class="toctree-l1">
              <span class="fa" style="font-size: 72%;"></span>
              &nbsp;<a href="/sitemap.xml">Sitemap</a>
            </li>
            <div style="padding-top: 2em;">
              <span class="fa"></span> Floris Laporte 2020
              <a
                href="/static/js/javascript.html"
                rel="jslicense"
                style="display: none;"
              >
                view javascript licenses</a
              >
            </div>
          </ul>
        </div>
      </div>
    </div>
    <script src="/static/js/localdates.js"></script>
    <script src="/static/js/externallinks.js"></script>
    <script src="/static/js/toggledarkmode.js"></script>
    
  </body>
</html>
